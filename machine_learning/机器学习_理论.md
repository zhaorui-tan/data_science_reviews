[TOC]

# 频率派 vs 贝叶斯派
对于有 n 个样本的样本集 `$X = (x_1, ..., x_n)$` 以及参数 `$\theta$`， 那么有 $X$ 服从概率分布 `$ P(x|\theta)$`


## 频率派
频率派认为 `$\theta$` 是一个未知的常量， 数据 $X$ 是一个随机变量，其服从一定的概率分布， 目的是通过极大似然估计 + 随机变量 $X$ 来估计出未知参数 `$\theta$` 。 `$ \theta_{MLE} = argmax_{\theta} ,, log P(X|\theta) $`


## 极大似然估计 - MLE

原理：利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。

极大似然估计提供了一种给定观察数据来评估模型参数的方法：模型已定，参数未知。经过若干次实验，观察结果，利用实验结果得到某个参数值能够使得样本出现的概率为最大，称为极大似然估计。

离散情况下参数 `$\theta$` 的似然函数：

`$ L(\theta) = L(X_1, X_2, \cdots, X_n; \theta) = \prod_{i=1}^n p(X_i| \theta) $`

极大似然估计： 对于给定的样本值`$(x_1, x_2, \cdots, x_n)$` 有： `$ \hat{\vec\theta}= \mathop {\arg \max}_{\vec\theta} L(\vec\theta ) $`

使得似然函数 `$L(x_1, x_2, \cdots, x_n; \theta)$`达到最大值的参数值 `$\hat{\theta} = \hat{\theta} (x_1, \cdots, x_n)$` 称为未知数 `$\theta$` 的最大似然估计值。

## 贝叶斯派
贝叶斯派认为 `$\theta$` 是一个随机变量，其服从一定的概率分布 `$p(\theta)$`。其采用最大后验估计来计算 `$P(\theta|X)$`。 `$ P(\theta|X) = \frac{P(X | \theta) P(\theta)}{P(X)} $`


先验： `$P(\theta)$` ， 似然： `$P(X|\theta)$` ， 后验：`$P(\theta|X)$`
`$ \theta_{MAP} = argmax_{\theta} ,  P(\theta | X) = argmax_{\theta} P(X|\theta)P(\theta) $`

## 最大后验估计 - MAP


MAP 的基础是贝叶斯公式： `$ 贝叶斯估计：P(\theta|X) = \frac{P(X | \theta) P(\theta)}{P(X)}= \frac{P(X | \theta) P(\theta)}{\int_{\theta} P(X|\theta)P(\theta)d{\theta}} \ 贝叶斯预测：p(\hat{x} | X) = \int_{\theta} p(\hat{x},\theta|X) d{\theta} = \int_{\theta} p(\hat{x}|\theta) p(\theta|X)d{\theta} $`
MAP 优化的就是后验概率， 目的是通过观测值使得后验概率最大： `$ \theta_{MAP} = argmax_{\theta} , , P(\theta | X) = argmax_{\theta} P(X|\theta)P(\theta) $`



---
---
---
---
---

# 距离度量方法

## 1. 欧式距离
衡量点之间的直线距离 
```math
二 维： d = \sqrt{(x_1 - x_2)^2 + (y_1 - y_2)^2} 

n 维： d = \sqrt{(x_1 - y_1)^2 + ... + (x_n - y_n)^2}
```

## 2. 曼哈顿距离
```math
二 维： d = |x_1 - x_2| + |y_1 - y_2| 

n 维：d = |x_1 - y_1| + ... + |x_n - y_n|
```

## 3. 余弦距离
将两个点看做是空间中的两个向量，通过衡量两向量之间的相似性来衡量样本之间的相似性。 
```math
二维：cos , \theta = \frac{x_1 * x_2 + y_1 * y_2}{\sqrt{(x_1^2 + y_1^2)} * \sqrt{x_2^2 + y_2^2}} \quad

或 \quad cos , \theta = \frac{a * b}{|a| * |b|} 

n 维： cos , \theta = \frac{x_1 * y_1 + ... + x_n * y_n}{\sqrt{x_1^2 + ... + x_n^2} * \sqrt{y_1^2 + ... + y_n^2}}
```

## 4. 切比雪夫距离
各对应坐标数值差的最大值。
```math
二维： d = max(|x_1 - x_2|, |y_1 - y_2|) 

n 维： d = max(|x_1 - y_1|, ... ,|x_n - y_n|)
```



# 偏差 vs 方差

## 定义
记在训练集 D 上学得的模型为

```math
f(x;D)
```

模型的期望预测为 

```math
\hat{f}(x) = E_D [f(x;D)]
```

## 偏差（Bias） 

```math
bias^2(x) = (\hat{f}(x) - y)^2
```


偏差度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；

## 方差（Variance） 
```math
var(x) = E_D[(f(x;D) - \hat{f}(x))^2]
```


方差度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响（模型的稳定性）；


```math
\varepsilon^2 = E_D[(y_D-y)^2]
```


噪声则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。

“偏差-方差分解”表明模型的泛化能力是由算法的能力、数据的充分性、任务本身的难度共同决定的。

### 理解概念
**偏差**： 表示模型在训练集上的表现，与训练误差成线性关系， 用于描述模型的拟合能力

**方差**： 表示模型在（开发集或测试集）与测试误差-训练误差成线性关系，用于描述模型的泛化能力。

### 四种情况

**偏差很低，方差很高：** 意味着训练误差很低，测试误差很高，此时发生了过拟合现象。

**偏差很高，方差很低：** 意味着训练误差，测试误差都很高，此时发生了欠拟合现在。

**偏差，方差都很高**： 意味着此时同时发生了欠拟合和过拟合现象。

**偏差很低，方差很低：**
意味着训练误差很低，测试误差也很低，表示我们的模型训练的结果很好。

### 偏差与欠拟合，方差与过拟合
偏差通常是由于我们定义的模型不合适或模型复杂度不够，所造成的现象为欠拟合。

方差主要是由于模型复杂度过高造成的， 所造成的现象是过拟合。

### 如何降低偏差（欠拟合）

- **加大模型规模（更换其余机器学习算法，神经网络可以增加每层神经元/神经网络层数）**：

偏差很高很有可能是因为模型的拟合能力差，对于传统机器学习算法，各个方法的拟合能力不同，选择一个拟合能力更好的算法往往能够得出很好的结果。

对于神经网络（拟合能力最强）而言，通过增加网络层数或增加每层单元数就能够很好的提高模型的拟合能力[3][4][5]。

- **根据误差分析结果来修改特征：**

我们需要将错误样本分类，判断可能是由于什么原因导致样本失败，在针对分析结果，增加或减少一些特征。

- **减少或去除正则化这可以避免偏差**，

但会增大方差。
- **修改模型结构，以适应你的问题**：

对于不同的问题，不同的模型结构会产生更好的结果，比如在CV中常用CNN，而在NLP领域常用LSTM。

## 如何降低方差（过拟合）
- 重新分析，清洗数据。

有时候，造成方差很大的原因往往是由于数据不良造成的，对于深度学习来说，有一个大规模，高质量的数据集是极为重要的。

- 添加更多的训练数据。

增大训练数据能够往往能够提高模型的泛化能力。可以采用数据增强技术。

- 加入正则化。
- 加入提前终止。

意思就是在训练误差变化很慢甚至不变的时候可以停止训练，这项技术可以降低方差，但有可能增大了偏差。 提前终止有助于我们能够在到达最佳拟合附近，避免进入过拟合状态。

- 通过特征选择减少输入特征的数量和种类。

显著减少特征数量能够提高模型的泛化能力，但模型的拟合能力会降低，这意味着，该技术可以减小方差，但可能会增大偏差。 不过在深度学习中，我们往往直接将所有特征放入神经网络中，交给算法来选择取舍。

- 减少模型规模，降低模型复杂度（每层神经元个数/神经网络层数）： 谨慎使用。

一般情况下，对于复杂问题如CV或NLP等问题不会降低模型复杂度，而对于简单问题，采用简单模型往往训练速度更快，效果很好。

- 根据误差分析结果修改输入特征。

修改模型架构，使之更适合你的问题。 一般可以选择简单模型的情况下，不选择复杂模型。

- 集成学习。

---
---
---
---
---


# 分类问题评估指标

## 混淆矩阵
TP： True Positives， 表示实际为正例且被分类器判定为正例的样本数

FP： False Positives， 表示实际为负例且被分类器判定为正例的样本数

FN： False Negatives， 表示实际为正例但被分类器判定为负例的样本数

TN： True Negatives， 表示实际为负例且被分类器判定为负例的样本数
一个小技巧， 第一个字母表示划分正确与否，

T 表示判定正确（判定正确），

F表示判定错误(False)；

第二个字母表示分类器判定结果， P表示判定为正例， N表示判定为负例。

## 几个常规的指标


### Accuracy：

```math
accuracy = \frac{TP + TN}{TP + FP + FN + TN}= \frac{正确预测的样本数}{所有的样本数} 
```

Accuracy 能够清晰的判断我们模型的表现，但有一个严重的缺陷： 在正负样本不均衡的情况下，占比大的类别往往会成为影响 Accuracy 的最主要因素，此时的 Accuracy 并不能很好的反映模型的整体情况。

### Precision： 

```math
Precision = \frac{TP}{TP + FP}

Precision = \frac{\sum_{l=1}^{L}TP_l}{\sum_{l=1}^LTP_l + FP_l} =

\frac{\text{label 预测为 l 且预测正确的样本个数}}{\text{label 预测为 l 样本个数}}
```
 

### Recall： 

```math
Recall = \frac{TP}{TP + FN} \\ Recall = \frac{\sum_{l=1}^L TP_l}{ \sum_{l=1}^LTP_l + FN_l} 

= \frac{\text{label 预测为 l 且预测正确的样本个数}}{\text{真实样本中所有 label 为 l 的样本个数}}
```


### Precision 与 Recall 的权衡

精确率高，意味着分类器要尽量在 “更有把握” 的情况下才将样本预测为正样本， 这意味着精确率能够很好的体现模型对于负样本的区分能力，精确率越高，则模型对负样本区分能力越强。

召回率高，意味着分类器尽可能将有可能为正样本的样本预测为正样本，这意味着召回率能够很好的体现模型对于正样本的区分能力，召回率越高，则模型对正样本的区分能力越强。

从上面的分析可以看出，精确率与召回率是此消彼长的关系， 如果分类器只把可能性大的样本预测为正样本，那么会漏掉很多可能性相对不大但依旧满足的正样本，从而导致召回率降低

## F1-Score
F1-Score 能够很好的评估模型，其主要用于二分类问题， 计算如下： 

```math
\text{F1} = \frac{2 \cdot \text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
```

而 更一般的有 `$F_{\beta}$` ： 

```math
F_{\beta} = \frac{(1 + \beta^2) \cdot \text{Precision} \cdot \text{Recall}}{ \beta^2 \times \text{Precision} + \text{Recall}}
```

其实， `$\beta$` 本质上是Recall， Precision 权重比， 当 `$\beta=2$` 时， `$F_2$` 表明 Recall 的权重要比Precision高，其影响更大， ； 当 `$\beta=0.5$` 时， `$F_{0.5}$` 表明 Recall 的权重要比Precision低， 对应的影响更小；

前面提到 F1 针对的是二分类，而更一般的是，对于多分类问题来说， F1 的计算有多种方式，可以参见 Scikit-Learn 中的评价指标，我们来分别介绍一下。

对于一个多分类问题，假设，对于分类 `$i$` 而言有：`$TP_i, FP_i, TN_i, FN_i$`， 那么各种 F1 的值计算如下。

### Macro F1： 宏平均

Macro 算法在计算 Precision 与 Recall 时是先分别计算每个类别的Precision 与 Recall， 然后再进行平均。
```math
Precision_i = \frac{TP_i}{TP_i + FP_i} 

\text{Precision}_{macro} = \frac{\sum_{i=1}^L \text{Precision}_i}{|L|}

\text{Recall}_i = \frac{TP_i}{TP_i + FN_i} 

\text{Recall}_{macro} = \frac{\sum{i=1}^L \text{Recall}_i}{|L|} 
```

那么我们就得到最终的 Macro F1 的计算为：
```math
\text{Macro F1} = \frac{2 \cdot \text{Precision}_{macro} \cdot \text{Recall}_{macro}}{\text{Precision}_{macro} + \text{Recall}_{macro}}
```
我们看到， Macro F1 本质上是所有类别的统计指标的算术平均值来求得的，这样单纯的平均忽略了样本之间分布可能存在极大不平衡的情况

Micro F1 ：微平均

Micro 算法在计算 Precision 与 Recall 时会将所有类直接放到一起来计算。

```math
\text{Precision}_{micro} = \frac{\sum{i=1}^L TP}{\sum_{i=1}^L TP + \sum_{i=1}^L FP}
```
    

```math
\text{Recall}_{micro} = \frac{\sum{i=1}^L TP}{\sum_{i=1}^L TP + \sum_{i=1}^L FN}

\text{Micro F1} = \frac{2 \cdot \text{Precision}_{micro} \cdot \text{Recall}_{micro}}{\text{Precision}_{micro} + \text{Recall}_{micro}}
```
                                                                        

## Macro vs Micro 

Macro 相对 Micro 而言，小类别起到的作用更大，举个例子而言，对于一个四分类问题有：



class | TP|  FP
---|---|---
class A| 1 TP| 1 FP
class B| 10 TP | 90 FP
class C| 1 TP| 1 FP
class D| 1 TP| 1 FP
那么对于 Precision 的计算有： 

```math
P_A = P_C = P_D = 0.5,P_B = 0.1 

P_{macro} = \frac{0.5 + 0.1 + 0.5 + 0.5}{4} = 0.4 

P_{micro} = \frac{1 + 10 + 1 + 1}{2 + 100 + 2 + 2} = 0.123
```


我们看到，对于 Macro 来说， 小类别相当程度上拉高了 Precision 的值，而实际上， 并没有那么多样本被正确分类，考虑到实际的环境中，真实样本分布和训练样本分布相同的情况下，这种指标明显是有问题的， 小类别起到的作用太大，以至于大样本的分类情况不佳。 而对于 Micro 来说，其考虑到了这种样本不均衡的问题， 因此在这种情况下相对较佳。

总的来说， 如果你的类别比较均衡，则随便； 如果你认为大样本的类别应该占据更重要的位置， 使用Micro； 如果你认为小样本也应该占据重要的位置，则使用 Macro； 如果 Micro << Macro ， 则意味着在大样本类别中出现了严重的分类错误； 如果 Macro << Micro ， 则意味着小样本类别中出现了严重的分类错误。

为了解决 Macro 无法衡量样本均衡问题，一个很好的方法是求加权的 Macro， 因此 Weighed F1 出现了。

### Weight F1

Weighted 算法算术 Macro 算法的改良版，是为了解决Macro中没有考虑样本不均衡的原因， 在计算 Precision与Recall 时候，各个类别的 Precision 与 Recall要乘以该类在总样本中的占比来求和：


```math
\text{Precision}i = \frac{TP_i}{TP_i + FP_i} 

\text{Precision}_{macro} = \frac{\sum_{i=1}^L \text{Precision}_i \times w_i}{|L|}

\text{Recall}i = \frac{TP_i}{TP_i + FN_i} 

\text{Recall}_{macro} = \frac{\sum{i=1}^L \text{Recall}_i \times w_i}{|L|} 

```


那么我们就得到最终的 Macro F1 的计算为： 
```math
\text{Macro weighted F1} = \frac{2 \cdot \text{Precision}_{macro} \cdot \text{Recall}_{macro}}{\text{Precision}_{macro} + \text{Recall}_{macro}}
```


## MCC ： 马修斯相关系数
MCC 主要用于衡量二分类问题，其综合考虑了 TP TN, FP , FN, **是一个比较均衡的指标， 对于样本不均衡情况下也可以使用** 。MCC的取值范围在 [-1, 1]， 取值为1 表示预测与实际完全一致， 取值为0表示预测的结果还不如随机预测的结果， -1 表示预测结果与实际的结果完全不一致。因此我们看到， MCC 本质上描述了预测结果与实际结果之间的相关系数。 


```math
MCC = \frac{TP \times TN - TP \times FN}{\sqrt{(TP + FP) \times (TP + FN) \times (TN + FP) \times (TN + FN)}}
```


值得注意的是，对于两个分类器而言，可能其中一个分类器的 F1 值较高，而其 MCC 值较低， 这表示单一的指标是无法衡量分类器的所有优点与缺点的。

## ROC 曲线
在分类任务中，测试部分通常是获得一个概率表示当前样本属于正例的概率， 我们往往会采取一个阈值，大于该阈值的为正例， 小于该阈值的为负例。 如果我们减小这个阈值， 那么会有更多的样本被识别为正类，这会提高正类的识别率，但同时会降低负类的识别率。

为了形象的描述上述的这种变化， 引入ROC曲线来评价一个分类器的好坏。 ROC 曲线主要关注两个指标： 

```math
\text{横坐标}: FPR = \frac{FP}{FP + FN} 

\text{纵坐标}: TPR = \frac{TP}{TP + FN}
```


其中， FPR 代表将负例错分为正例的概率， TPR 表示能将正例分对的概率， 如果我们增大阈值， 则 TPR 会增加，而对应的FPR也会增大， 而绘制ROC曲线能够帮助我们找到二者的均衡点，下图很清晰的描述了ROC 曲线关系：



#### 在 ROC 曲线中， 有：

FPR = 0, TPR = 0： 表示将每一个实例都预测为负类
FPR = 1, TPR = 1：表示将每一个实例都预测为正例
FPR = 0, TPR = 1：为最优分类点
分类器对应的ROC曲线应该尽可能靠近坐标轴的左上角， 而对角线的位置意味着分类器的效果和随机猜测一样的差。

**ROC曲线在测试集中的样本分布发生变化的时候能够保持不变。**但遗憾的是，很多时候， ROC 曲线并不能清晰的说明哪个分类器的效果更好， 而 AUC 恰恰能够对分类器做出直观的评价。

AUC：Area under Curve
AUC 为ROC 曲线下的面积， 这个面积的数值介于0到1之间， 能够直观的评价出分类器的好坏， AUC的值越大， 分类器效果越好。

AUC = 1： 完美分类器， 采用该模型，不管设定什么阈值都能得出完美预测（绝大多数时候不存在）
0.5 < AUC < 1： 优于随机猜测，分类器好好设定阈值的话，有预测价值

AUC = 0.5： 跟随机猜测一样，模型没有预测价值
AUC < 0.5 ：比随机猜测还差，但是如果反着预测，就优于随机猜测。
值得一提的是，两个模型的AUC 相等并不代表模型的效果相同， 比如这样：



实际场景中， AUC 的确是非常常用的一种指标。

需要注意的是， 在多分类场景下的 ROC 曲线以及 AUC 值， 此时 ROC 曲线应该有多个， 而AUC 的计算如下： 


```math
AUC = \frac{2}{|C|(|C|-1)} \sum_{i=1}^{|C|} AUC_i, 

C , 表示类别数量
```


## P-R 曲线
P-R 曲线其横坐标为 Recall， 纵坐标为 Precision， 其能帮助我们很好的做出权衡



在上图中，我们发现， A 完全包住了C， 着意味着A 的Precision 与 Recall 都高于C， A优于C。 而对比 A,B， 二者存在交叉的情况，此时采用曲线下面积大小衡量性能，面积越大，性能越好，此处的A优于B。


## 最后
对于最终分类指标的选择， 在不同数据集，不同场景，不同时间下都会有不同的选择，但往往最好选出一个指标来做优化，对于二分类问题，我目前用 AUC 比较多一些， 多分类我还是看 F1 值。

---
---
---
---
---

# 项目流程
## 1. 抽象成数学问题
明确问题是进行机器学习的第一步。机器学习的训练过程通常都是一件非常耗时的事情，胡乱尝试时间成本是非常高的。

这里的抽象成数学问题，指的我们明确我们可以获得什么样的数据，目标是一个分类还是回归或者是聚类的问题。

## 2. 获取数据
数据决定了机器学习结果的上限，而算法只是尽可能逼近这个上限。

数据要有代表性，否则必然会过拟合。
分类问题要考虑到样本均衡问题，不同类别的数据数量不要有数个数量级的差距。
对数据的量级有一个评估，多少个样本，多少个特征，可以估算出其对内存的消耗程度，判断训练过程中内存是否能够放得下。如果放不下就得考虑改进算法或者使用一些降维的技巧了。如果数据量实在太大，那就要考虑分布式了。
## 3. 特征预处理与特征选择
特征预处理、数据清洗是很关键的步骤，往往能够使得算法的效果和性能得到显著提高。

归一化、离散化、因子化、缺失值处理、去除共线性等，数据挖掘过程中很多时间就花在它们上面。

特征选择：

筛选出显著特征、摒弃非显著特征，需要机器学习工程师反复理解业务。特征选择好了，非常简单的算法也能得出良好、稳定的结果。这需要运用特征有效性分析的相关技术，如 相关系数、卡方检验、平均互信息、条件熵、后验概率、逻辑回归权重等方法。


### 数据清洗
数据清洗主要包括数据采样和样本过滤。

1. 样本采样

- 分类问题： 需要注意样本均衡问题，合适选择正负比例。
- 回归问题： 需要采集数据。
- 对于采样得到的样本，根据需要，需要设定样本权重。
- 当模型不能使用全部的数据来训练时，需要对数据进行采样，设定一定的采样率。

2. 样本过滤:结合业务情况进行数据的过滤

3. 异常点检测：

- 偏差检测，例如聚类，最近邻等。
- 基于统计的异常点检测算法, 例如极差，四分位数间距，均差，标准差等，这种方法适合于挖掘单变量的数值型数据。全距(Range)，又称极差，是用来表示统计资料中的变异量数(measures of variation) ，其最大值与最小值之间的差距；四分位距通常是用来构建箱形图，以及对概率分布的简要图表概述。
- 基于距离的异常点检测算法，主要通过距离方法来检测异常点，将数据集中与大多数点之间距离大于某个阈值的点视为异常点，主要使用的距离度量方法有绝对距离 ( 曼哈顿距离 ) 、欧氏距离和马氏距离等方法。
- 基于密度的异常点检测算法，考察当前点周围密度，可以发现局部异常点，例如LOF算法

### 数据清洗
#### 1. 如何处理数据中的缺失值
有些特征可能因为无法采样或者没有观测值而缺失，此时需要对这些缺失的特征值进行特殊处理。

##### 1. 缺失值较多
如果该特征中的缺失值较多，则应该直接舍弃，否则反而可能引入较大噪声，造成反效果。

##### 2. 缺失值较少
即当缺失值在 10% 以内时，我们可以采用多种方式处理：

将缺失值当一个特征处理，用 一个异常值表示， 如0： 


```
data_train.fillna(0)
```


用均值填充：


```
data_train.fillna(data_train.mean())
```


以上下数据填充：


```
data_train.fillna(method='pad')  # 上一个数据填充
data_train.fillna(method='bfill')  # 下一个数据填充
```

插值法


```
data_train.interpolate() # 即估计中间点的值
```

用随机森林等算法拟合

将数据分为有值和缺失值2份，对有值的数据采用随机森林拟合，然后对有缺失值的数据进行预测，用预测的值来填充。


### 特征常见处理手段
##### 1.数值归一化
归一化的目的是将所有的特征都统一到一个大致相同的数值区间中。

从梯度下降的角度来看，对于两个特征x1，x2， x1的范围远远大于x2，在学习率相同的情况下，x1的更新速度会大于x2，需要较多的迭代才能得到最优解。


- 函数归一化： 
- min-max 归一化， 
- 零均值归一化（参考 Normalization 一节）
- 分维度归一化
- 排序归一化

##### 2. 离散化
连续值的离散化：

**等值划分：** 将特征按照值域进行均分，每一段内的取值等同处理。例如某个特征的取值范围为[0，10]，我们可以将其划分为10段，[0，1)，[1，2)，...，[9，10)。

**等量划分** 是根据样本总数进行均分，每段等量个样本划分为1段。

区别：例如距离特征，取值范围［0，3000000］，现在需要切分成10段，如果按照等比例划分的话，会发现绝大部分样本都在第1段中。使用等量划分就会避免这种问题，最终可能的切分是[0，100)，[100，300)，[300，500)，..，[10000，3000000]，前面的区间划分比较密，后面的比较稀疏。

### 3. 共线性问题 -- TODO
对于回归算法而言， 其首先假设回归模型的解释变量之间不存在线性关系， 即解释变量X1，X2，……，Xk中的任何一个都不能是其他解释变量的线性组合。如果违背这一假定，即线性回归模型中某一个解释变量与其他解释变量间存在线性关系，就称线性回归模型中存在多重共线性。

多重共线性违背了解释变量间不相关的古典假设，将给普通最小二乘法带来严重后果。其实，简单来说，就是特征冗余，容易导致过拟合。

##### 1. 如何判定共线性问题？
- 相关性分析。当相关性系数高于0.8，表明存在多重共线性；但相关系数低，并不能表示不存在多重共线性
- 方差膨胀因子VIF。当VIF大于5或10时，代表模型存在严重的共线性问题；
条件系数检验。 当条件数大于100、1000时，代表模型存在严重的共线性问题。
##### 2. 如何消除共线性问题？
通常可通过PCA降维、逐步回归法和LASSO回归等方法消除共线性。

### 4. 如何进行特征选择？
##### 1. 特征分类
- 相关特征： 对于特定的任务和场景有一定帮助的属性，这些属性能有效提升算法性能。
- 无关特征：在特定的任务和场景下完全无用的属性，这些属性对对象在本目标环境下完全无用。
- 冗余特征：同样是在特定的任务和场景下具有一定帮助的属性，但这类属性已过多的存在，不具有产生任何新的信息的能力。

##### 2. 如何考虑特征选择
可以从以下两个方面来选择特征：

- 特征是否具有发散性：某个特征若在所有样本上的都是一样的或者接近一致，即方差非常小。 也就是说所有样本的都具有一致的表现，那这些就不具有任何信息。
- 特征与目标的相关性：与目标相关性高的特征，应当优选选择。

##### 3. 特征选择方法分类
- 过滤法：按照发散性或者相关性对各个特征进行评分，设定阈值或者待选择阈值的个数，选择特征。
- 包装法：根据目标函数(通常是预测效果评分)，每次选择若干特征，或者排除若干特征。
- 嵌入法：先使用某些机器学习的算法和模型进行训练，得到各个特征的权值系数，根据系数从大到小选择特征。

##### 4. 特征选择目的
- 减少特征维度，使模型泛化能力更强，减少过拟合;
降低任务目标的学习难度；
- 一组优秀的特征通常能有效的降低模型复杂度，提升模型效率

##### 5. 关联规则
https://www.jianshu.com/p/7d459ace31ab

关联规则挖掘是一种基于规则的机器学习算法，该算法可以在大数据库中发现感兴趣的关系。它的目的是利用一些度量指标来分辨数据库中存在的强规则。也即是说关联规则挖掘是用于知识发现，而非预测，所以是属于无监督的机器学习方法。

从所有可能规则的集合中选择感兴趣的规则需要利用一些度量方法来筛选和过滤，下面的三种方法。

关联规则的三个度
1. **支持度**

`$ Support(X→Y) = P(X,Y) / P(I) = P(X∪Y) / P(I) = num(XUY) / num(I) $` 

支持度表示 item-set {X,Y} 在总 item-set 里出现的概率。其中， $I$ 表示总事务集， num()表示事务集里特定 item-set 出现的次数。比如：$num(I)$ 表示总事务集的个数，$num(X∪Y)$ 表示含有 {X,Y} 的事务集的个数（个数也叫次数）。

2. **置信度**

`$ Confidence(X→Y) = P(Y|X) = P(X,Y) / P(X) = P(XUY) / P(X) $`

置信度表示在先决条件X发生的情况下，由关联规则”X→Y“推出Y的概率。即在含有X的项集中，含有Y的可能性。

3. **提升度**

`$ Lift(X→Y) = P(Y|X) / P(Y) $`

提升度表示含有X的条件下，同时含有Y的概率，与Y总体发生的概率之比。

++**满足最小支持度和最小置信度的规则，叫做“强关联规则”。**++

- `$Lift(X→Y)>1$`，“X→Y”是有效的强关联规则。
- `$Lift(X→Y) <=1$`，“X→Y”是无效的强关联规则。
- 特别地，`$Lift(X→Y) =1$`，X与Y相互独立。



## 4. 训练模型与调优
模型选择与超参数调优。这需要我们对算法的原理有深入的理解。理解越深入，就越能发现问题的症结，提出良好的调优方案。

## 5. 模型诊断
通过模型诊断来确定模型调优的方向与思路。

过拟合、欠拟合 判断是模型诊断中至关重要的一步。常见的方法如交叉验证，绘制学习曲线等。
误差分析 也是机器学习至关重要的步骤。通过观察误差样本，全面分析误差产生误差的原因：是参数的问题还是算法选择的问题，是特征的问题还是数据本身的问题 ？
这个过程需要反复迭代，调优-诊断-调优

## 6. 模型融合
一般来说，模型融合后都能使得效果有一定提升。而且效果很好。 工程上，主要提升算法准确度的方法是分别在模型的前端（特征清洗和预处理，不同的采样模式）与后端（模型融合）上下功夫。因为他们比较标准可复制，效果比较稳定。而直接调参的工作不会很多，毕竟大量数据训练起来太慢了，而且效果难以保证。

## 7. 上线运行
模型在线上运行的效果直接决定模型的成败。 不单纯包括其准确程度、误差等情况，还包括其运行的速度(时间复杂度)、资源消耗程度（空间复杂度）、稳定性是否可接受。

---
---
---
---
---

# 无监督学习 vs 监督学习

## 监督学习模型
监督学习的任务是学习一个模型，对给定的输入预测相应的输出，这个模型的一般形式维一个决策函数或一个条件概率分布。

决策函数：输入 X 返回 Y；其中 Y 与一个阈值比较，然后根据比较结果判定 X 的类别 $$ Y = f(X) $$

条件概率分布：输入 X 返回 X 属于每个类别的概率；将其中概率最大的作为 X 所属的类别 `$ P = (Y|X) $`

## 远程监督（Distant Supervision）

思想： 将已有知识库对应到丰富的非结构化数据中，从而生成大量训练数据，进而训练出一个效果不错的模型。

远程监督在关系抽取，短语挖掘等方向上得到广泛应用。

---
---
---
---
---

# 判别模型 vs 生成模型

## 判别模型
代表：K 近邻、感知机（神经网络）、决策树、逻辑斯蒂回归、最大熵模型、SVM、提升方法、条件随机场

思想： 由数据直接学习决策函数 `Y=f(X)$` 或条件概率分布 `$P(Y|X)$` 作为预测的模型。

理解： 直观的说，判别模型学习的是类别之间的最优分隔面，反映的是不同类数据之间的差异

举例：要确定一个羊是山羊还是绵羊，用判别模型的方法是从历史数据中学习到模型，然后通过提取这只羊的特征来预测出这只羊是山羊的概率，是绵羊的概率。

## 生成模型
代表：朴素贝叶斯、隐马尔可夫模型、混合高斯模型、贝叶斯网络、马尔可夫随机场

思想：由数据学习得到联合概率密度分布 $P(X,Y)$， 然后求出条件概率分布 $P(Y|X)$ 作为预测的模型： $$ P(Y|X) = \frac{P(X,Y)}{P(X)} $$

举例：利用生成模型是根据山羊的特征首先学习出一个山羊的模型，然后根据绵羊的特征学习出一个绵羊的模型，然后从这只羊中提取特征，放到山羊模型中看概率多少，放到绵羊模型中看概率多少，哪个大就是哪个。

## 判别模型 vs 生成模型
由生成模型能够得到判别模型，但由判别模型得不到生成模型

当存在“隐变量”时，只能使用生成模型

隐变量：当我们找不到引起某一现象的原因时，就把这个在起作用，但无法确定的因素，叫“隐变量”

### 判别方法的特点：

缺点：不能反映训练数据本身的特性。

优点：它寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。

优点：直接面对预测，往往学习的准确率更高。
优点：由于直接学习P(Y|X)或P(X)，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。

### 生成方法的特点：

优点： 可以从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度。但它不关心到底划分各类的那个分类边界在哪。

优点：生成方法的学习收敛速度更快，即当样本容量增加的时候，学到的模型可以更快的收敛于真实模型。

优点：当存在隐变量时，仍可以用生成方法学习。此时判别方法就不能用。

缺点：学习和计算过程比较复杂

---
---
---
---
---

# 集成学习

组合多个弱监督模型以得到一个更好更全面的强监督模型，其思想在于：即便某一个弱分类器得到了错误的预测，其他的弱分类器也可以将错误纠正回来。

集成方法奏效的原因是不同的模型通常不会在测试集上产生相同的误差。集成模型能至少与它的任一成员表现得一样好。如果成员的误差是独立的，集成将显著提升模型的性能。

学习策略推荐：

数据集大： 划分成多个小数据集，学习多个模型进行组合。
数据集小： 利用 Bootstrap 方法进行抽样，得到多个数据集，分别训练多个模型再进行组合。

## Bootstrap：
一种有放回的抽样方法，目的是为了得到统计量的分布以及置信空间。
- 采用有放回抽样方法从原始样本中抽取一定数量的样本,
- 根据抽出的样本计算想要得到的统计量T。
- 重复上述N次（一般大于1000），得到N个统计量T
- 根据这N个统计量，即可计算出统计量的置信区间

## Bagging
代表模型： 随机森林， Bagging meta-estimator

先通过采样构造 k 个不同的数据集，学习得到k 个基学习器， 基学习器之间不存在依赖关系，可同时生成。

更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 2/3 的实例

Bagging 的基本思路：

- 利用Bootstrap对训练集随机采样，重复进行 T 次
- 基于每个采样集训练一个弱学习器，得到 T 个弱学习器
- 预测时，分类问题采用投票方式， 回归问题采用 N 个模型预测平均方式。


## Boosting
代表模型：AdaBoost， XGBoost， GBDT， Light GBM， CatBoost

学习一系列弱学习器，然后组合成一个强学习器。基于串行策略：弱学习器之间存在依赖关系，新的学习器需要根据上一个学习器生成。

Boosting基本思路：
- 先从初始训练集训练一个弱学习器，初始训练集各个样本权重相同
- 根据上一个弱学习器的表现，调整样本权重，是的分类错误的样本得到更多关注
- 基于调整后的样本分布，训练下一个弱学习器
- 测试时，对各基学习器加权得到最终结果


## Stacking

训练一个模型用于组合其他各个模型。首先我们先训练多个不同的模型，然后把之前训练的各个模型的输出为输入来训练一个模型，以得到一个最终的输出。

Stacking 基本思路：首先我们先训练多个不同的模型，然后把之前训练的各个模型的输出为输入来训练一个模型，以得到一个最终的输出。

- 先从初始训练集训练 T 个不同的初级学习器;
- 利用每个初级学习器的输出构建一个次级数据集，该数据集依然使用初始数据集的标签；
- 根据新的数据集训练次级学习器；
- 多级学习器的构建过程类似。


## Boosting, Bagging 与偏差，方差
Boosting 能提升弱分类器性能的原因是降低了偏差；Bagging 则是降低了方差；

Boosting：

Boosting 的基本思路就是在不断减小模型的训练误差（拟合残差或者加大错类的权重），加强模型的学习能力，从而减小偏差；
但 Boosting 不会显著降低方差，因为其训练过程中各基学习器是强相关的，缺少独立性。


Bagging：

对 n 个独立不相关的模型预测结果取平均，方差是原来的 1/n；
假设所有基分类器出错的概率是独立的，超过半数基分类器出错的概率会随着基分类器的数量增加而下降。